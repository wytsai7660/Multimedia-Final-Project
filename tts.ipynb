{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please run this script in Google Colab(Or any other IDEs that support iPython).\n",
        "For 1st use, run all the scripts.\n",
        "And then you can use function `train(audio_file)` and `gen(message, audio_text)` to generate new audio `fake.wav`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u_H4HRDSsm-T",
        "outputId": "1132184d-df3a-43bd-8e2d-8221ff6fe7ce"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/fishaudio/fish-speech.git\n",
        "\n",
        "# 安装 pytorch\n",
        "!pip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n",
        "\n",
        "# (Ubuntu / Debian 用户) 安装 sox + ffmpeg\n",
        "!apt install libsox-dev ffmpeg\n",
        "\n",
        "# (Ubuntu / Debian 用户) 安装 pyaudio\n",
        "!apt install build-essential \\\n",
        "    cmake \\\n",
        "    libasound-dev \\\n",
        "    portaudio19-dev \\\n",
        "    libportaudio2 \\\n",
        "    libportaudiocpp0\n",
        "\n",
        "# 安裝模型\n",
        "!huggingface-cli download fishaudio/fish-speech-1.5 --local-dir checkpoints/fish-speech-1.5\n",
        "\n",
        "# 安装 fish-speech\n",
        "!pip3 install -e ./fish-speech/\n",
        "%cd ./fish-speech/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuXPa2vtKRvA",
        "outputId": "f2917d9d-cf1d-4833-ea62-5fc8bc50411d"
      },
      "outputs": [],
      "source": [
        "# 導入語音樣本\n",
        "import subprocess\n",
        "\n",
        "%cd ./fish-speech/\n",
        "\n",
        "def train(filename: str = \"../chiang2.mp3\"):\n",
        "    cmd = [\n",
        "        \"python\", \"tools/vqgan/inference.py\",\n",
        "        \"-i\", filename,\n",
        "        \"--checkpoint-path\", \"checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n",
        "    ]\n",
        "    subprocess.run(cmd, check=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AK7j2zBmLxLq"
      },
      "outputs": [],
      "source": [
        "# 用於生成語音\n",
        "def gen(message: str, \n",
        "        prompt: str = \"Okay. So you can see compare these two audio signals, uhh you can see the maximum of second signal, uhh you can see the maximum dB is like over minus one.\") -> None:\n",
        "    cmd1 = [\n",
        "        \"python\", \"tools/llama/generate.py\",\n",
        "        \"--text\", message,\n",
        "        \"--prompt-text\", prompt,\n",
        "        \"--prompt-tokens\", \"fake.npy\",\n",
        "        \"--checkpoint-path\", \"checkpoints/fish-speech-1.5\",\n",
        "        \"--num-samples\", \"2\",\n",
        "        \"--compile\"\n",
        "    ]\n",
        "    subprocess.run(cmd1, check=True)\n",
        "\n",
        "    cmd2 = [\n",
        "        \"python\", \"tools/vqgan/inference.py\",\n",
        "        \"-i\", \"codes_0.npy\",\n",
        "        \"--checkpoint-path\", \"checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n",
        "    ]\n",
        "    subprocess.run(cmd2, check=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lhIy1wdrOP8J"
      },
      "outputs": [],
      "source": [
        "# 使用範例\n",
        "mes = \"Hi, today we'll introduce multimedia.\"\n",
        "train()\n",
        "gen(mes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And then you'll get a file `fake.wav` in `./fish-speech` folder. This is the file it generate."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
